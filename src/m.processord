#!/bin/bash
############################################################################
#
# MODULE:       m.processord
# AUTHOR(S):    Michael Rabotin (rabotin@supagro.inra.fr)
# PURPOSE:      Process Order calcul for an oriented hydrological network
# REQUIREMENTS: m.testtype
#
# COPYRIGHT:    (C) 2009 UMR LISAH - OpenFluid
#
#               This program is free software under the GNU General Public
#               License (>=v2). Read the file COPYING that comes with GRASS
#               for details.
#
#############################################################################
#%Module
#%  description: Process Order calcul for an oriented hydrological network
#%END
#%option
#% key: input
#% type: string
#% gisprompt: old,vector,vector
#% description: Input line vector name
#% key_desc : name
#% required : yes
#%END
#%option
#% key: output
#% type: string
#% gisprompt: new,vector,vector
#% description: Output line vector name
#% key_desc : name
#% required : yes
#%END
#%option
#% key: column
#% type: string
#% description: Column name for Process Order calcul
#% required : yes
#%END

if [ "$1" != "@ARGS_PARSED@" ] ; then
  exec g.parser "$0" "$@"
fi

INPUT="$GIS_OPT_INPUT"
OUTPUT="$GIS_OPT_OUTPUT"
COLUMN="$GIS_OPT_COLUMN"

eval `g.gisenv`
: ${GISDBASE?} ${LOCATION_NAME?} ${MAPSET?}


#GRASS testing
if  [ -z "$GISBASE" ]
then
	echo ""
	echo "You must start GRASS to launch this program"
	echo ""
	exit 2
fi

#GRASS version testing, must be >= 6.3

Gversion1=`g.version |cut -d" " -f2 |cut -d"." -f1`
Gversion2=`g.version |cut -d" " -f2 |cut -d"." -f2`

if [ $Gversion1 -ge 6 ];then
	if [ $Gversion1 = 6 ] && [ $Gversion2 -lt 3 ];then 
		g.message -e message="You must have GRASS version 6.3.0 or higher"
		exit 2
	fi
else
	g.message -e message="You must have GRASS version 6.3.0 or higher"
	exit 2

fi

#awk testing
if [ ! -x "`which awk`" ];then
  g.message -e message="awk required, please install awk our gawk first"
  exit 2
fi

#perl testing
if [ ! -x "`which perl`" ];then
  g.message -e message="perl required, please install perl first"
  exit 2
fi

#test driver (dbf only accepted)
if [ "`db.connect -p|head -n 1 |cut -d":" -f2 `" != "dbf" ]
then
	g.message -e message="Sorry, but only dbf driver accepted "
  exit 2
fi 

# setting environment, so that awk works properly in all languages
unset LC_ALL
LC_NUMERIC=C
export LC_NUMERIC

# all above OK - proceed: set up temporary files
TMP="`g.tempfile pid=$$`"
if [ $? -ne 0 ] || [ -z "$TMP" ] ; then
    echo "ERROR: Unable to create temporary files." 1>&2
    exit 2
fi
rm -f $TMP
PROG=`basename $0 | sed 's/\./_/g'`
NOW=$(date +"%F-%X")
LOGFILE="$PROG-$NOW.log"

#cleanup procedure
cleanup()
{
  \rm -f $TMP
   
   for ((u=1;u<=20;u+=1))
  do
    rm -f $TMP.${PROG}.$u
  done

  g.mremove -f vect="$INPUT"_processtmp* --q
  if [ -e ~/$LOGFILE ] && [ ! -s ~/$LOGFILE ] ;then
		rm -f ~/$LOGFILE
	fi
  
}

# what to do in case of user break:
exitprocedure()
{
  echo -e "\nUser break!"
  cleanup
  exit 2
}
# shell check for user break (signal list: trap -l)
trap "exitprocedure" 2 3 15

# dependancies testing
if [ ! -x "`which m.testtype`" ];then
  g.message -e message="m.testtype subscript required, please install it first"
  exit 2
fi

#test if output vector map already exists
eval `g.findfile element=vector file="$OUTPUT" `
if [ "$file" ] ; then
  if [ -z "$GRASS_OVERWRITE" ] || [ "$GRASS_OVERWRITE" -eq 0 ]; then
    g.message -w message="<$OUTPUT> already exists in this mapset or in another mapset of this location. Use the --o flag to overwrite." 1>&2
    exit 2
  else
    g.message -w message="<$OUTPUT>  already exists and will be overwritten"
  fi
fi

#test if OUTPUT vector name is allowed
v.in.region output=$OUTPUT --q  |grep -v "SQL" 2>$TMP.${PROG}.20
	
if [ -s "$TMP.${PROG}.20" ];then
	g.message -w message="Illegal vector map name <$OUTPUT>" 1>&2
    exit 2
else
	g.remove vect=$OUTPUT --q  
fi


#test if input temporary vector map already exist
g.mlist type=vect pattern="$INPUT"_processtmp*  > $TMP.${PROG}.1
if [ -s "$TMP.${PROG}.1" ];then
  g.message -w message="<$INPUT>_processtmp name for temporay vector files is already used in this mapset or in another mapset of this location"
  cleanup
  exit 2

fi

# test if INPUT exists
g.findfile element=vector mapset=${MAPSET?} file=${INPUT} > /dev/null
if [ $? -ne 0 ] ; then
 g.message -e message="<$INPUT> vector doesn't exist !"
 cleanup
 exit 2
fi

m.testtype input=$INPUT > $TMP.${PROG}.2

#if input vector map is not a line vector, exit program
if [ "`cat $TMP.${PROG}.2`" != "line" ] ; then
	g.message -e message="<$INPUT> doesn't exist or isn't a vector line !!"
	cleanup
	exit 2
fi

# test on COLUMN value
v.info -c map=$INPUT --q |cut -d"|" -f2 |grep "^$COLUMN$" > $TMP.${PROG}.3
if [ ! -s "$TMP.${PROG}.3" ];then
  g.message -e message="The column <$COLUMN> doesn't exist !!"
  cleanup
  exit 2
fi

g.region vect=$INPUT --q 2>>~/$LOGFILE

# copy of the vetcor map
g.copy vect=$INPUT,"$INPUT"_processtmp --q  2>>~/$LOGFILE

#creation of the column PO
v.db.addcol map="$INPUT"_processtmp columns="PO INTEGER" --q 2>>~/$LOGFILE

#updating values of  COLUMN==0, PO ==1
v.db.update map="$INPUT"_processtmp column=$COLUMN value=0 --q 2>>~/$LOGFILE
v.db.update map="$INPUT"_processtmp column=PO value=1 --q 2>>~/$LOGFILE

# making v.net to build a network
v.net -c input="$INPUT"_processtmp output="$INPUT"_processtmp1 operation=nodes --q 2>>~/$LOGFILE

#$TMP.${PROG}.4 contains : line_category start_point_category end_point_category
v.net input="$INPUT"_processtmp1 operation=report --q > $TMP.${PROG}.4 2>>~/$LOGFILE

#$TMP.${PROG}.5 contains : point_category line_category[,line_category...]
v.net input="$INPUT"_processtmp1 operation=nreport --q > $TMP.${PROG}.5 2>>~/$LOGFILE

#searching the dangles for process order =1
grep -v "," $TMP.${PROG}.5 |cut -d" " -f2 > $TMP.${PROG}.6 2>>~/$LOGFILE
if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
fi
#removing the dangles which have  startpoint in with on or several segments

cut -d" " -f3 $TMP.${PROG}.4 > $TMP.${PROG}.7 2>>~/$LOGFILE
#$TMP.${PROG}.7 contains only the endpoints of the network
for h in `cat $TMP.${PROG}.6`;do
	varh=$h
	awk -F" " <$TMP.${PROG}.4 '$1=='$varh'' |cut -d" " -f2 >$TMP.${PROG}.8 2>>~/$LOGFILE
	if [ -s "$TMP.${PROG}.8" ]
	then
		startpt=`cat $TMP.${PROG}.8`	
		awk -F" " <$TMP.${PROG}.7 '$1=='$startpt''  >$TMP.${PROG}.9 2>>~/$LOGFILE
		#if $TMP.${PROG}.9 contains one or several points , that means that the startpoint is in contact with other segments
		if [ -s "$TMP.${PROG}.9" ]
		then
			echo "$h" >> $TMP.${PROG}.10 2>>~/$LOGFILE
		fi	 
	else
		> $TMP.${PROG}.10 2>>~/$LOGFILE
	fi
done
if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
fi
#if  $TMP.${PROG}.10 is not empty, we must remove these dangles from  $TMP.${PROG}.6
if [ -s "$TMP.${PROG}.10" ]
then
	sort -k1n $TMP.${PROG}.6 > $TMP.${PROG}.11 2>>~/$LOGFILE
	sort -k1n $TMP.${PROG}.10 > $TMP.${PROG}.12 2>>~/$LOGFILE
	diff $TMP.${PROG}.11 $TMP.${PROG}.12|grep -v "d"|cut -d" " -f2 > $TMP.${PROG}.13 2>>~/$LOGFILE
	#$TMP.${PROG}.13 contains all the good dangles 
else
	cp $TMP.${PROG}.6 $TMP.${PROG}.13 2>>~/$LOGFILE
fi 

	rm -f $TMP.${PROG}.10

if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
fi
typeset -i process
process=1

#we manage the values for the segments with Process Order = 1
for i in `cat $TMP.${PROG}.13`;do
			v.db.update map="$INPUT"_processtmp1 column=$COLUMN value=$process where="cat=$i" --q 2>>~/$LOGFILE
			v.db.update map="$INPUT"_processtmp1 column=PO value=-1 where="cat=$i" --q 2>>~/$LOGFILE
done
if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
fi
#loop command until there are value of 1 in  PO 
v.db.select -c map="$INPUT"_processtmp1 column=PO where="PO = 1" --q > $TMP.${PROG}.14 2>>~/$LOGFILE


while [ -s "$TMP.${PROG}.14" ]
do

	v.db.select -c map="$INPUT"_processtmp1 column=cat where="PO = 1" --q > $TMP.${PROG}.15 2>>~/$LOGFILE
	v.extract input="$INPUT"_processtmp1 output="$INPUT"_processtmp2 type=line file=$TMP.${PROG}.15 --q 2>>~/$LOGFILE
	v.net -c input="$INPUT"_processtmp2 output="$INPUT"_processtmp3 operation=nodes --q 2>>~/$LOGFILE
	v.net input="$INPUT"_processtmp3 operation=report --q > $TMP.${PROG}.16 2>>~/$LOGFILE
	v.net input="$INPUT"_processtmp3 operation=nreport --q > $TMP.${PROG}.17 2>>~/$LOGFILE
	if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
	fi
	#searching all the dangles
	grep -v "," $TMP.${PROG}.17 |cut -d" " -f2 > $TMP.${PROG}.6 2>>~/$LOGFILE

	#removing the dangles with startpoint in contact with one or more segments

	cut -d" " -f3 $TMP.${PROG}.16 > $TMP.${PROG}.7 2>>~/$LOGFILE
	#$TMP.${PROG}.7 contains only the endpoint of the network
	for h in `cat $TMP.${PROG}.6`;do
		varh=$h
		awk -F" " <$TMP.${PROG}.16 '$1=='$varh'' |cut -d" " -f2 >$TMP.${PROG}.8 2>>~/$LOGFILE
		if [ -s "$TMP.${PROG}.8" ]
		then
			startpt=`cat $TMP.${PROG}.8`	
			awk -F" " <$TMP.${PROG}.7 '$1=='$startpt''  >$TMP.${PROG}.9 2>>~/$LOGFILE
			#if $TMP.${PROG}.9 contains one or more points , that means that the startpoint is in contact with other segments
			if [ -s "$TMP.${PROG}.9" ]
			then
				echo "$h" >> $TMP.${PROG}.10 2>>~/$LOGFILE
			fi
		else
			> $TMP.${PROG}.10 2>>~/$LOGFILE
		fi
	done
	if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
	fi
	#if  $TMP.${PROG}.10 is not empty , we need to remove these dangles from  $TMP.${PROG}.6
	if [ -s "$TMP.${PROG}.10" ]
	then
		uniq -u $TMP.${PROG}.10 > $TMP.${PROG}.18 2>>~/$LOGFILE
		uniq -d $TMP.${PROG}.10 >> $TMP.${PROG}.18 2>>~/$LOGFILE
		sort -k1n $TMP.${PROG}.6 > $TMP.${PROG}.11 2>>~/$LOGFILE
		sort -k1n $TMP.${PROG}.18 > $TMP.${PROG}.12 2>>~/$LOGFILE
		diff $TMP.${PROG}.11 $TMP.${PROG}.12|grep -v "d"|grep -v "c"|grep -v "-"|cut -d" " -f2 > $TMP.${PROG}.13 2>>~/$LOGFILE
		
		#$TMP.${PROG}.13 contains all the good dangles
	else
		cp $TMP.${PROG}.6 $TMP.${PROG}.13 2>>~/$LOGFILE
	fi
	
	
		rm -f $TMP.${PROG}.10
		rm -f $TMP.${PROG}.18
	
	process=$process+1
	
	for j in `cat $TMP.${PROG}.13`;do
		v.db.update map="$INPUT"_processtmp1 column=$COLUMN value=$process where="cat=$j" --q 2>>~/$LOGFILE
		v.db.update map="$INPUT"_processtmp1 column=PO value=-1 where="cat=$j" --q 2>>~/$LOGFILE
		
	done

	g.remove vect="$INPUT"_processtmp2,"$INPUT"_processtmp3 --q 2>>~/$LOGFILE
	if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
	fi
	v.db.select -c map="$INPUT"_processtmp1 column=PO where="PO = 1" --q > $TMP.${PROG}.14 2>>~/$LOGFILE
	if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
	fi
done

g.rename vect="$INPUT"_processtmp1,$OUTPUT --q 2>>~/$LOGFILE
v.db.dropcol map=$OUTPUT column=PO --q 2>>~/$LOGFILE
if [ ! -z "`cat ~/$LOGFILE`" ];then
		g.message -e message="Errors append during calculation. Check the home/user/$LOGFILE file for details"
		cleanup
		exit 2
fi
#cleanup procedure
cleanup
exit 0
